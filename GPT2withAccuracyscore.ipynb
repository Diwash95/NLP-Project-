{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5dd5eaedb17646cd9de581f63e4f8ce6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_378109344f01489683aabf7b725a027c",
              "IPY_MODEL_f2403d04efe54ff5b466ab7064fbcb9e",
              "IPY_MODEL_a7275946686543d49383d7fbc2d4db1f"
            ],
            "layout": "IPY_MODEL_6e1ae2c264984a94b4332d9b4a0a5c67"
          }
        },
        "378109344f01489683aabf7b725a027c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d43ae5e23c954889b61965515b3d2783",
            "placeholder": "​",
            "style": "IPY_MODEL_a46d61510d784e1bbc1d0105b4b3a6db",
            "value": "Downloading: 100%"
          }
        },
        "f2403d04efe54ff5b466ab7064fbcb9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b3b03dd5cd6485e9cd3f04e0515f0a7",
            "max": 230,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9eda130450194048b3fdc872f0f59bf5",
            "value": 230
          }
        },
        "a7275946686543d49383d7fbc2d4db1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d45693deccf344d18ad979ee836d436d",
            "placeholder": "​",
            "style": "IPY_MODEL_dc80ee3f676548ff99dfa066bedf3638",
            "value": " 230/230 [00:00&lt;00:00, 3.18kB/s]"
          }
        },
        "6e1ae2c264984a94b4332d9b4a0a5c67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d43ae5e23c954889b61965515b3d2783": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a46d61510d784e1bbc1d0105b4b3a6db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b3b03dd5cd6485e9cd3f04e0515f0a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9eda130450194048b3fdc872f0f59bf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d45693deccf344d18ad979ee836d436d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc80ee3f676548ff99dfa066bedf3638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzDAfoWL5mtx",
        "outputId": "06f73269-5645-44ef-d65e-eac924e5a71c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'transformers' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/huggingface/transformers \\\n",
        "&& cd transformers \\\n",
        "&& git checkout a3085020ed0d81d4903c50967687192e3101e770 "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ./transformers\n",
        "!pip install tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "id": "CSe5MA1I-uaz",
        "outputId": "8159f7f7-e98b-4bab-ec5a-1ae7c6c168cc"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./transformers\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (1.21.6)\n",
            "Requirement already satisfied: tokenizers==0.0.11 in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (0.0.11)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (1.22.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (3.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (0.1.96)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (0.0.49)\n",
            "Requirement already satisfied: botocore<1.26.0,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.3.0) (1.25.4)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.3.0) (0.5.2)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.3.0) (1.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.26.0,>=1.25.4->boto3->transformers==2.3.0) (1.25.11)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.26.0,>=1.25.4->boto3->transformers==2.3.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.26.0,>=1.25.4->boto3->transformers==2.3.0) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.3.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.3.0) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.3.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.3.0) (1.1.0)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-2.3.0-py3-none-any.whl size=458565 sha256=b136be461b370cae6e993571afdaf8af77e6a681f32da0949fa56d55b8abceed\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-aghzu9lq/wheels/49/62/f4/6730819eed4e6468662b1519bf3bf46419b2335990c77f8767\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 2.3.0\n",
            "    Uninstalling transformers-2.3.0:\n",
            "      Successfully uninstalled transformers-2.3.0\n",
            "Successfully installed transformers-2.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "transformers"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (2.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir dataset \\\n",
        "&& cd dataset \\\n",
        "&& wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json \\\n",
        "&& wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oY64C0zA-uX6",
        "outputId": "13ab349a-1733-48d6-bd4d-a5d07ed6419d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘dataset’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers.data.processors.squad import SquadResult, SquadV2Processor, SquadExample\n",
        "from transformers.data.metrics.squad_metrics import compute_predictions_logits\n",
        "def intoList(tensor):\n",
        "    return tensor.detach().cpu().tolist()\n",
        "# for running predictions on given models\n",
        "def run_prediction(model, model_name, tokenizer, question_texts, context_text):\n",
        "    processor = SquadV2Processor()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)    \n",
        "    # setting configuration\n",
        "    n_best_size = 1\n",
        "    max_answer_length = 30\n",
        "    do_lower_case = True\n",
        "    null_score_diff_threshold = 0.0\n",
        "    \"\"\"Setup function to compute predictions\"\"\"\n",
        "    examples = []\n",
        "    for i, question_text in enumerate(question_texts):\n",
        "        example = SquadExample(\n",
        "            qas_id=str(i),\n",
        "            question_text=question_text,\n",
        "            context_text=context_text,\n",
        "            answer_text=None,\n",
        "            start_position_character=None,\n",
        "            title=\"Predict\",\n",
        "            is_impossible=False,\n",
        "            answers=None,\n",
        "        )\n",
        "        examples.append(example)\n",
        "    features, dataset = squad_convert_examples_to_features(\n",
        "        examples=examples,\n",
        "        tokenizer=tokenizer,\n",
        "        max_seq_length=384,\n",
        "        doc_stride=128,\n",
        "        max_query_length=64,\n",
        "        is_training=False,\n",
        "        return_dataset=\"pt\",\n",
        "        threads=1,\n",
        "    )\n",
        "    sampler = SequentialSampler(dataset)\n",
        "    Dataloader = DataLoader(dataset, sampler=sampler, batch_size=10)\n",
        "    all_results = []\n",
        "    for batch in Dataloader:\n",
        "        model.eval()\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        with torch.no_grad():\n",
        "            inputs = {\n",
        "                \"input_ids\": batch[0],\n",
        "                \"attention_mask\": batch[1],\n",
        "                \"token_type_ids\": batch[2],\n",
        "            }\n",
        "            example_indices = batch[3]\n",
        "            outputs = model(**inputs)\n",
        "            for i, example_index in enumerate(example_indices):\n",
        "                eval_feature = features[example_index.item()]\n",
        "                unique_id = int(eval_feature.unique_id)\n",
        "                output = [intoList(output[i]) for output in outputs]\n",
        "                start_logits, end_logits = output\n",
        "                result = SquadResult(unique_id, start_logits, end_logits)\n",
        "                all_results.append(result)\n",
        "\n",
        "    Pred_File = model_name + \"_predictions.json\"\n",
        "    nbest_file =  model_name + \"_nbest_predictions.json\"\n",
        "    outputnulllogoddsfile =  model_name + \"_null_predictions.json\"\n",
        "    predictions = compute_predictions_logits(\n",
        "        examples,\n",
        "        features,\n",
        "        all_results,\n",
        "        n_best_size,\n",
        "        max_answer_length,\n",
        "        do_lower_case,\n",
        "        Pred_File,\n",
        "        nbest_file,\n",
        "        outputnulllogoddsfile,\n",
        "        False,  \n",
        "        True,  \n",
        "        null_score_diff_threshold,\n",
        "        tokenizer,\n",
        "    )\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "LyJ8XmRp-uSt"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gpt2 model\n",
        "def runGpt2(model, question_texts, context_text):\n",
        "    predictions = []    \n",
        "    for question in question_texts:\n",
        "        prediction = model(question=question, context=context_text)\n",
        "        predictions.append(prediction['answer'])        \n",
        "    return predictions"
      ],
      "metadata": {
        "id": "4Ktjy094I4g5"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "# for using pretrained gpt2 model\n",
        "gpt2_model = pipeline('question-answering')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "5dd5eaedb17646cd9de581f63e4f8ce6",
            "378109344f01489683aabf7b725a027c",
            "f2403d04efe54ff5b466ab7064fbcb9e",
            "a7275946686543d49383d7fbc2d4db1f",
            "6e1ae2c264984a94b4332d9b4a0a5c67",
            "d43ae5e23c954889b61965515b3d2783",
            "a46d61510d784e1bbc1d0105b4b3a6db",
            "0b3b03dd5cd6485e9cd3f04e0515f0a7",
            "9eda130450194048b3fdc872f0f59bf5",
            "d45693deccf344d18ad979ee836d436d",
            "dc80ee3f676548ff99dfa066bedf3638"
          ]
        },
        "id": "n4A7wa9CI4Wu",
        "outputId": "3d287497-b1e1-4c59-fd76-de4251221282"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/230 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5dd5eaedb17646cd9de581f63e4f8ce6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# given dataset to test model\n",
        "corpus = \"Musk was born to a Canadian mother and White South African father, and raised in Pretoria, South Africa. He briefly attended the University of Pretoria before moving to Canada at age 17 to avoid conscription. He was enrolled at Queen's University and transferred to the University of Pennsylvania two years later, where he received a bachelor's degree in economics and physics. He moved to California in 1995 to attend Stanford University but decided instead to pursue a business career, co-founding the web software company Zip2 with his brother Kimbal. The startup was acquired by Compaq for $307 million in 1999. The same year, Musk co-founded online bank X.com, which merged with Confinity in 2000 to form PayPal. The company was bought by eBay in 2002 for $1.5 billion.\"\n",
        "query = [\"What is startup by elon musk?\"]"
      ],
      "metadata": {
        "id": "rIaESZkGJ5Ow"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Gpt2output = runGpt2(gpt2_model, query, corpus)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoQqkO59I4Rv",
        "outputId": "9f62be5d-9de3-4be3-be29-75868488db3b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 52.51it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 6472.69it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('question: ',*query, sep=\" \") \n",
        "print('Answer:   ',*Gpt2output, sep=\" \") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twqeg6uXI4Od",
        "outputId": "53504341-1487-4bd9-a105-5ba83f140761"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question:  What is startup by elon musk?\n",
            "Answer:    online bank X.com,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ACCURACY"
      ],
      "metadata": {
        "id": "y-GM3sV4LuWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from sklearn.metrics import accuracy_score\n",
        "with open('dataset/dev-v2.0.json', 'r') as fp:\n",
        "    Testx = json.load(fp)\n",
        "Contxts = []\n",
        "for data in Testx['data']:\n",
        "    for paragraph in data['paragraphs']:\n",
        "        context = paragraph['context']\n",
        "        questions = []\n",
        "        answers = []        \n",
        "        for qas in paragraph['qas']:\n",
        "            question = qas['question']\n",
        "            q_answers = qas['answers']\n",
        "            if len(q_answers) > 0:\n",
        "                questions.append(question)\n",
        "                answers.append(q_answers[0]['text'])\n",
        "            else:\n",
        "                p_answers = qas['plausible_answers']\n",
        "                if len(p_answers) > 0:\n",
        "                    questions.append(question)\n",
        "                    answers.append(p_answers[0]['text'])\n",
        "        Contxts.append({'context': context, 'questions':questions, 'answers': answers})"
      ],
      "metadata": {
        "id": "4BrIJk-OLt2m"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get x and y predicts\n",
        "def Testx_prediction_gpt2(model, Contxts):\n",
        "    y_predict =[]\n",
        "    y_test =[]\n",
        "    max_record = 0\n",
        "    # limiting the records \n",
        "    for Contxt in Contxts[0:2]:\n",
        "        print(max_record)\n",
        "        predictions = runGpt2(model, Contxt['questions'], Contxt['context'])\n",
        "        # answers\n",
        "        y_test.extend(Contxt['answers'])\n",
        "        # predictions\n",
        "        for prediction in predictions:\n",
        "            y_predict.append(prediction)            \n",
        "        max_record += 1      \n",
        "    return y_predict, y_test"
      ],
      "metadata": {
        "id": "I13rI1sMLtxC"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict, y_test = Testx_prediction_gpt2(gpt2_model, Contxts)\n",
        "gpt2_accuracy = accuracy_score(y_test, y_predict)\n",
        "print(\"Accuracy of GPT-2 is:\",gpt2_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4My5kvtLtsX",
        "outputId": "2e31464f-1e7c-4605-9d49-7117221af398"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 96.25it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 8224.13it/s]\n",
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 75.67it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 11244.78it/s]\n",
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 68.57it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 10672.53it/s]\n",
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 107.90it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 10058.28it/s]\n",
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 85.20it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 10565.00it/s]\n",
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 85.16it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 7169.75it/s]\n",
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 80.35it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 12945.38it/s]\n",
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 76.24it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 7724.32it/s]\n",
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 64.38it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 6223.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 51.07it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 11335.96it/s]\n",
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 40.89it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 7626.01it/s]\n",
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 44.99it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 7825.19it/s]\n",
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 45.13it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 9619.96it/s]\n",
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 53.63it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 9776.93it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OW7_tbfKLtpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kEN-4IrGLtmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "khIqoqfKLtjX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}